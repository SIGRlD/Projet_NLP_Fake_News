{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from donnees.nettoyage import FakeNews_Task3_2022_V0\n",
    "from donnees.utils import FakeNewsDataset, ajuster_canaux\n",
    "from embedding import GloVeModel, tokeniser\n",
    "from modeles import baseLSTM, baseBiLSTM, train_seq_var, baseCNN, train_seq_fix, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer et nettoyer les donnees\n",
    "data_train = FakeNews_Task3_2022_V0(\"./donnees/FakeNews_Task3_2022_V0/Task3_train_dev/Task3_english_training.csv\",\"train\")\n",
    "data_dev = FakeNews_Task3_2022_V0(\"./donnees/FakeNews_Task3_2022_V0/Task3_train_dev/Task3_english_dev.csv\",\"dev\")\n",
    "data_test = FakeNews_Task3_2022_V0(\"./donnees/FakeNews_Task3_2022_V0/Task3_Test/English_data_test_release_with_rating.csv\",\"test\")\n",
    "print(f\"Entrainement : {data_train.shape[0]} | Validation : {data_dev.shape[0]} | Test : {data_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster les variables\n",
    "data_train[\"full_text\"] = data_train.title+\" \"+data_train.text\n",
    "data_train[\"label$true\"] = np.where(data_train.our_rating==\"true\",1,0)\n",
    "data_train[\"label$false\"] = np.where(data_train.our_rating.str.contains(\"false\"),1,0)\n",
    "data_train[\"label\"] = np.select([data_train.our_rating.str.contains(\"false\"),data_train.our_rating==\"true\"],[0,1],2)\n",
    "data_dev[\"full_text\"] = data_dev.title+\" \"+data_dev.text\n",
    "data_dev[\"label$true\"] = np.where(data_dev.our_rating==\"true\",1,0)\n",
    "data_dev[\"label$false\"] = np.where(data_dev.our_rating.str.contains(\"false\"),1,0)\n",
    "data_dev[\"label\"] = np.select([data_dev.our_rating.str.contains(\"false\"),data_dev.our_rating==\"true\"],[0,1],2)\n",
    "data_test[\"full_text\"] = data_test.title+\" \"+data_test.text\n",
    "data_test[\"label$true\"] = np.where(data_test.our_rating==\"true\",1,0)\n",
    "data_test[\"label$false\"] = np.where(data_test.our_rating.str.contains(\"false\"),1,0)\n",
    "data_test[\"label\"] = np.select([data_test.our_rating.str.contains(\"false\"),data_test.our_rating==\"true\"],[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "# Choisir glove ou word2Vec\n",
    "glove = GloVeModel(\"./donnees/glove.6B/glove.6B.100d.txt\")\n",
    "# word2Vec = KeyedVectors.load_word2vec_format(\"./donnees/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees d'entrainement\n",
    "tokens_train = tokeniser(data_train.full_text,modele=glove,pad=True)\n",
    "if isinstance(tokens_train,torch.Tensor):\n",
    "    print(tokens_train.shape)\n",
    "else:\n",
    "    print(len(tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles d'entrainement\n",
    "cible_train_real = torch.tensor(data_train[\"label$true\"],dtype=torch.float32)\n",
    "cible_train_fake = torch.tensor(data_train[\"label$false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees de validation\n",
    "tokens_dev = tokeniser(data_dev.full_text,modele=glove,pad=True)\n",
    "if isinstance(tokens_dev,torch.Tensor):\n",
    "    print(tokens_dev.shape)\n",
    "else:\n",
    "    print(len(tokens_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles de validation\n",
    "cible_dev_real = torch.tensor(data_dev[\"label$true\"],dtype=torch.float32)\n",
    "cible_dev_fake = torch.tensor(data_dev[\"label$false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees de test\n",
    "tokens_test = tokeniser(data_test.full_text,modele=glove,pad=True)\n",
    "if isinstance(tokens_test,torch.Tensor):\n",
    "    print(tokens_test.shape)\n",
    "else:\n",
    "    print(len(tokens_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles pour l'evaluation\n",
    "cible_train_dev_real = torch.cat((cible_train_real,cible_dev_real))\n",
    "cible_test_real = torch.tensor(data_test[\"label$true\"],dtype=torch.int)\n",
    "cible_train_dev_fake = torch.cat((cible_train_fake,cible_dev_fake))\n",
    "cible_test_fake = torch.tensor(data_test[\"label$false\"],dtype=torch.int)\n",
    "cible_train_dev = torch.cat((torch.tensor(data_train[\"label\"]),torch.tensor(data_dev[\"label\"])))\n",
    "cible_test = torch.tensor(data_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer datasets pour les modeles (seulement pour sequences de longueur fixe)\n",
    "max_mots = max(tokens_train.shape[1],tokens_dev.shape[1],tokens_test.shape[1])   # ATTENTION! Peut etre tres eleve, peut changer pour une valeur au choix\n",
    "dataset_train_real = FakeNewsDataset(ajuster_canaux(tokens_train,max_mots),cible_train_real)\n",
    "dataset_dev_real = FakeNewsDataset(ajuster_canaux(tokens_dev,max_mots),cible_dev_real)\n",
    "dataset_test_real = FakeNewsDataset(ajuster_canaux(tokens_test,max_mots),cible_test_real)\n",
    "dataset_train_fake = FakeNewsDataset(ajuster_canaux(tokens_train,max_mots),cible_train_fake)\n",
    "dataset_dev_fake = FakeNewsDataset(ajuster_canaux(tokens_dev,max_mots),cible_dev_fake)\n",
    "dataset_test_fake = FakeNewsDataset(ajuster_canaux(tokens_test,max_mots),cible_test_fake)\n",
    "max_mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM-RNN \n",
    "Pour séquences de texte de longueur variable ou fixe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"real\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "lstm_real = baseLSTM(input_size=100,hidden_size=100,seq=\"var\",device=\"mps\")\n",
    "optimizer = optim.Adam(lstm_real.parameters(),lr=1e-4)\n",
    "lstm_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_var(lstm_real,optimizer,max_epochs=10,X_train=tokens_train,y_train=cible_train_real,X_val=tokens_dev,y_val=cible_dev_real,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_real = torch.cat((lstm_real.predict(tokens_train),lstm_real.predict(tokens_dev)))\n",
    "pred_test_real = lstm_real.predict(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_real,pred_train_dev_real,\"entrainement + dev\")\n",
    "evaluation(cible_test_real,pred_test_real,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"fake\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "lstm_fake = baseLSTM(input_size=100,hidden_size=100,seq=\"var\",device=\"mps\")\n",
    "optimizer = optim.Adam(lstm_fake.parameters(),lr=1e-4)\n",
    "lstm_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_var(lstm_fake,optimizer,max_epochs=10,X_train=tokens_train,y_train=cible_train_fake,X_val=tokens_dev,y_val=cible_dev_fake,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_fake = torch.cat((lstm_fake.predict(tokens_train),lstm_fake.predict(tokens_dev)))\n",
    "pred_test_fake = lstm_fake.predict(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_fake,pred_train_dev_fake,\"entrainement + dev\")\n",
    "evaluation(cible_test_fake,pred_test_fake,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les predictions\n",
    "pred_train_dev = np.select([(pred_train_dev_real==0)*(pred_train_dev_fake==1),(pred_train_dev_real==1)*(pred_train_dev_fake==0)],[0,1],2)\n",
    "pred_test = np.select([(pred_test_real==0)*(pred_test_fake==1),(pred_test_real==1)*(pred_test_fake==0)],[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele combine\n",
    "print(\"Justesse entrainement + dev : {:.2f}%\".format(100*accuracy_score(cible_train_dev,pred_train_dev)))\n",
    "print(\"Justesse test : {:.2f}%\".format(100*accuracy_score(cible_test,pred_test)))\n",
    "ConfusionMatrixDisplay.from_predictions(cible_train_dev,pred_train_dev,normalize=None)\n",
    "plt.title(f\"Matrice de confusion - Données entrainement + dev\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "ConfusionMatrixDisplay.from_predictions(cible_test,pred_test,normalize=None)\n",
    "plt.title(f\"Matrice de confusion - Données test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi-LSTM-RNN \n",
    "Pour séquences de texte de longueur variable ou fixe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"real\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "bilstm_real = baseBiLSTM(input_size=100,hidden_size=100,seq=\"var\",device=\"mps\")\n",
    "optimizer = optim.Adam(bilstm_real.parameters(),lr=1e-4)\n",
    "bilstm_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_var(bilstm_real,optimizer,max_epochs=10,X_train=tokens_train,y_train=cible_train_real,X_val=tokens_dev,y_val=cible_dev_real,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_real = torch.cat((bilstm_real.predict(tokens_train),bilstm_real.predict(tokens_dev)))\n",
    "pred_test_real = bilstm_real.predict(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_real,pred_train_dev_real,\"entrainement + dev\")\n",
    "evaluation(cible_test_real,pred_test_real,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"fake\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "bilstm_fake = baseBiLSTM(input_size=100,hidden_size=100,seq=\"var\",device=\"mps\")\n",
    "optimizer = optim.Adam(bilstm_fake.parameters(),lr=1e-4)\n",
    "bilstm_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_var(bilstm_fake,optimizer,max_epochs=10,X_train=tokens_train,y_train=cible_train_fake,X_val=tokens_dev,y_val=cible_dev_fake,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_fake = torch.cat((bilstm_fake.predict(tokens_train),bilstm_fake.predict(tokens_dev)))\n",
    "pred_test_fake = bilstm_fake.predict(tokens_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_fake,pred_train_dev_fake,\"entrainement + dev\")\n",
    "evaluation(cible_test_fake,pred_test_fake,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les predictions\n",
    "pred_train_dev = np.select([(pred_train_dev_real==0)*(pred_train_dev_fake==1),(pred_train_dev_real==1)*(pred_train_dev_fake==0)],[0,1],2)\n",
    "pred_test = np.select([(pred_test_real==0)*(pred_test_fake==1),(pred_test_real==1)*(pred_test_fake==0)],[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele combine\n",
    "print(\"Justesse entrainement + dev : {:.2f}%\".format(100*accuracy_score(cible_train_dev,pred_train_dev)))\n",
    "print(\"Justesse test : {:.2f}%\".format(100*accuracy_score(cible_test,pred_test)))\n",
    "ConfusionMatrixDisplay.from_predictions(cible_train_dev,pred_train_dev,normalize=None)\n",
    "plt.title(f\"Matrice de confusion - Données entrainement + dev\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "ConfusionMatrixDisplay.from_predictions(cible_test,pred_test,normalize=None)\n",
    "plt.title(f\"Matrice de confusion - Données test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "Pour séquences de texte de longueur fixe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"real\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "cnn_real = baseCNN(input_size=100,in_channels=max_mots,out_channels=128,kernel_size=5,device=\"mps\")\n",
    "optimizer = optim.Adam(cnn_real.parameters(),lr=1e-4)\n",
    "cnn_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(cnn_real,optimizer,max_epochs=10,Xy_train=dataset_train_real,Xy_val=dataset_dev_real,taille_batch=1,melanger=True,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_real = torch.cat((cnn_real.predict(dataset_train_real.X),cnn_real.predict(dataset_dev_real.X)))\n",
    "pred_test_real = cnn_real.predict(dataset_test_real.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_real,pred_train_dev_real,\"entrainement + dev\")\n",
    "evaluation(cible_test_real,pred_test_real,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"fake\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "cnn_fake = baseCNN(input_size=100,in_channels=max_mots,out_channels=128,kernel_size=5,device=\"mps\")\n",
    "optimizer = optim.Adam(cnn_fake.parameters(),lr=1e-4)\n",
    "cnn_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(cnn_fake,optimizer,max_epochs=10,Xy_train=dataset_train_fake,Xy_val=dataset_dev_fake,taille_batch=1,melanger=True,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_fake = torch.cat((cnn_fake.predict(dataset_train_fake.X),cnn_fake.predict(dataset_dev_fake.X)))\n",
    "pred_test_fake = cnn_fake.predict(dataset_test_fake.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_fake,pred_train_dev_fake,\"entrainement + dev\")\n",
    "evaluation(cible_test_fake,pred_test_fake,\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les predictions\n",
    "pred_train_dev = np.select([(pred_train_dev_real==0)*(pred_train_dev_fake==1),(pred_train_dev_real==1)*(pred_train_dev_fake==0)],[0,1],2)\n",
    "pred_test = np.select([(pred_test_real==0)*(pred_test_fake==1),(pred_test_real==1)*(pred_test_fake==0)],[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele combine\n",
    "print(\"Justesse entrainement + dev : {:.2f}%\".format(100*accuracy_score(cible_train_dev,pred_train_dev)))\n",
    "print(\"Justesse test : {:.2f}%\".format(100*accuracy_score(cible_test,pred_test)))\n",
    "ConfusionMatrixDisplay.from_predictions(cible_train_dev,pred_train_dev,normalize=None)\n",
    "plt.title(f\"Matrice de confusion - Données entrainement + dev\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "ConfusionMatrixDisplay.from_predictions(cible_test,pred_test,normalize=None)\n",
    "plt.title(f\"Matrice de confusion - Données test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IFT714",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
