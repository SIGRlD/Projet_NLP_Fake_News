{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ..donnees.nettoyage import load_dataset, clean_dataset, add_columns\n",
    "from ..donnees.utils import FakeNewsDataset, ajuster_canaux\n",
    "from ..donnees.embedding import GloVeModel, tokeniser\n",
    "from .modeles import CNN, CNNRNN, train_seq_fix, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer et nettoyer les donnees\n",
    "# Entrainement\n",
    "data_train = load_dataset(\"../donnees/FakeNews_Task3_2022_V0/Task3_english_training.csv\")\n",
    "data_train = clean_dataset(data_train)\n",
    "data_train = add_columns(data_train)\n",
    "# Validation\n",
    "data_dev = load_dataset(\"../donnees/FakeNews_Task3_2022_V0/Task3_english_dev.csv\")\n",
    "data_dev = clean_dataset(data_dev)\n",
    "data_dev = add_columns(data_dev)\n",
    "# Test\n",
    "data_test = load_dataset(\"../donnees/FakeNews_Task3_2022_V0/English_data_test_release_with_rating.csv\")\n",
    "data_test = clean_dataset(data_test)\n",
    "data_test = add_columns(data_test)\n",
    "\n",
    "print(f\"Entrainement : {data_train.shape[0]} | Dev : {data_dev.shape[0]} | Test : {data_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "glove = GloVeModel(\"../donnees/glove.6B/glove.6B.100d.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees d'entrainement\n",
    "# Si pad=True, retourne un tenseur, sinon retourne une liste\n",
    "tokens_train = tokeniser(data_train.full_text,modele=glove,pad=True)\n",
    "print(tokens_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles d'entrainement\n",
    "cible_train_fake = torch.tensor(data_train[\"false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees dev\n",
    "# Si pad=True, retourne un tenseur, sinon retourne une liste\n",
    "tokens_dev = tokeniser(data_dev.full_text,modele=glove,pad=True)\n",
    "print(tokens_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles dev\n",
    "cible_dev_fake = torch.tensor(data_dev[\"false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees de test\n",
    "# Si pad=True, retourne un tenseur, sinon retourne une liste\n",
    "tokens_test = tokeniser(data_test.full_text,modele=glove,pad=True)\n",
    "print(tokens_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles test\n",
    "cible_test_fake = torch.tensor(data_test[\"false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée\n",
    "tokens_subtrain, tokens_valid, cible_subtrain_fake, cible_valid_fake = train_test_split(tokens_train,cible_train_fake,test_size=0.2,random_state=42,stratify=cible_train_fake)\n",
    "print(\"Sous-entrainement :\",tokens_subtrain.shape)\n",
    "print(\"Validation :\",tokens_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer datasets pour les modeles\n",
    "max_mots = max(tokens_train.shape[1],tokens_dev.shape[1],tokens_test.shape[1])   # ATTENTION! Peut etre tres eleve, peut changer pour une valeur au choix\n",
    "dataset_train_fake = FakeNewsDataset(ajuster_canaux(tokens_train,max_mots),cible_train_fake)\n",
    "dataset_subtrain_fake = FakeNewsDataset(ajuster_canaux(tokens_subtrain,max_mots),cible_subtrain_fake)\n",
    "dataset_valid_fake = FakeNewsDataset(ajuster_canaux(tokens_valid,max_mots),cible_valid_fake)\n",
    "dataset_dev_fake = FakeNewsDataset(ajuster_canaux(tokens_dev,max_mots),cible_dev_fake)\n",
    "dataset_test_fake = FakeNewsDataset(ajuster_canaux(tokens_test,max_mots),cible_test_fake)\n",
    "max_mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybride CNN-RNN \n",
    "Pour séquences de texte de longueur fixe.  \n",
    "Source : https://www.sciencedirect.com/science/article/pii/S2667096820300070"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "hybrid_fake = CNNRNN(input_size=100,in_channels=max_mots,out_channels1=1024,out_channels2=256,kernel_size=5,hidden_size=50,p_dropout=0.5,device=\"mps\")\n",
    "optimizer = optim.Adam(hybrid_fake.parameters(),lr=1e-4)\n",
    "hybrid_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(hybrid_fake,optimizer,max_epochs=10,Xy_train=dataset_subtrain_fake,Xy_val=dataset_valid_fake,taille_batch=1,melanger=True,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "hybrid_fake.eval()\n",
    "pred_train_fake = hybrid_fake.predict(dataset_train_fake.X)\n",
    "pred_dev_fake = hybrid_fake.predict(dataset_dev_fake.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_fake,pred_train_fake,\"entrainement\")\n",
    "evaluation(cible_dev_fake,pred_dev_fake,\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(hybrid_fake.state_dict(),\"../modeles/hybrid_fake.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid_fake.eval()\n",
    "data_train[\"hybrid_score\"] = hybrid_fake.predict_proba(dataset_train_fake.X)\n",
    "data_dev[\"hybrid_score\"] = hybrid_fake.predict_proba(dataset_dev_fake.X)\n",
    "data_test[\"hybrid_score\"] = hybrid_fake.predict_proba(dataset_test_fake.X)\n",
    "data_train[\"hybrid_pred\"] = hybrid_fake.predict(dataset_train_fake.X)\n",
    "data_dev[\"hybrid_pred\"] = hybrid_fake.predict(dataset_dev_fake.X)\n",
    "data_test[\"hybrid_pred\"] = hybrid_fake.predict(dataset_test_fake.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "Pour séquences de texte de longueur fixe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "cnn_fake = CNN(input_size=100,in_channels=max_mots,out_channels1=512,out_channels2=128,out_channels3=32,out_channels4=8,kernel_size=3,p_dropout=(0.2,0.5),device=\"mps\")\n",
    "optimizer = optim.Adam(cnn_fake.parameters(),lr=1e-4)\n",
    "cnn_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(cnn_fake,optimizer,max_epochs=15,Xy_train=dataset_subtrain_fake,Xy_val=dataset_valid_fake,taille_batch=10,melanger=True,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "cnn_fake.eval()\n",
    "pred_train_fake = cnn_fake.predict(dataset_train_fake.X)\n",
    "pred_dev_fake = cnn_fake.predict(dataset_dev_fake.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_fake,pred_train_fake,\"entrainement\")\n",
    "evaluation(cible_dev_fake,pred_dev_fake,\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_fake.state_dict(),\"../modeles/cnn_fake.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_fake.eval()\n",
    "data_train[\"cnn_score\"] = cnn_fake.predict_proba(dataset_train_fake.X)\n",
    "data_dev[\"cnn_score\"] = cnn_fake.predict_proba(dataset_dev_fake.X)\n",
    "data_test[\"cnn_score\"] = cnn_fake.predict_proba(dataset_test_fake.X)\n",
    "data_train[\"cnn_pred\"] = cnn_fake.predict(dataset_train_fake.X)\n",
    "data_dev[\"cnn_pred\"] = cnn_fake.predict(dataset_dev_fake.X)\n",
    "data_test[\"cnn_pred\"] = cnn_fake.predict(dataset_test_fake.X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFNN\n",
    "Pour données au niveau \"phrases\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ..donnees.embedding import TfIdf\n",
    "from .modeles import FFNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding Tf-Idf\n",
    "modele = TfIdf(pd.concat((data_train.full_text,data_dev.full_text)),max_df=0.90,min_df=0.1)\n",
    "vocab_size = modele.X.toarray().shape[1]\n",
    "print(\"Taille du vocabulaire :\",vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainement\n",
    "tokens_train = torch.from_numpy(modele.embedding_newdata(data_train.full_text).toarray()).type(torch.float32).requires_grad_(False)\n",
    "cible_train_fake = torch.tensor(data_train[\"false\"],dtype=torch.float32)\n",
    "dataset_train_fake = FakeNewsDataset(tokens_train,cible_train_fake)\n",
    "# Dev\n",
    "tokens_dev = torch.from_numpy(modele.embedding_newdata(data_dev.full_text).toarray()).type(torch.float32).requires_grad_(False)\n",
    "cible_dev_fake = torch.tensor(data_dev[\"false\"],dtype=torch.float32)\n",
    "dataset_dev_fake = FakeNewsDataset(tokens_dev,cible_dev_fake)\n",
    "# Test\n",
    "tokens_test = torch.from_numpy(modele.embedding_newdata(data_test.full_text).toarray()).type(torch.float32).requires_grad_(False)\n",
    "cible_test_fake = torch.tensor(data_test[\"false\"],dtype=torch.float32)\n",
    "dataset_test_fake = FakeNewsDataset(tokens_test,cible_test_fake)\n",
    "print(\"Entrainement :\",tokens_train.shape)\n",
    "print(\"Dev :\",tokens_dev.shape)\n",
    "print(\"Test :\",tokens_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation croisée\n",
    "tokens_subtrain, tokens_valid, cible_subtrain_fake, cible_valid_fake = train_test_split(tokens_train,cible_train_fake,test_size=0.2,random_state=42,stratify=cible_train_fake)\n",
    "print(\"Sous-entrainement :\",tokens_subtrain.shape)\n",
    "print(\"Validation :\",tokens_valid.shape)\n",
    "dataset_subtrain_fake = FakeNewsDataset(tokens_subtrain,cible_subtrain_fake)\n",
    "dataset_valid_fake = FakeNewsDataset(tokens_valid,cible_valid_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "ffnn_fake = FFNN(input_size=vocab_size,in_size=1024,hidden_size1=256,hidden_size2=64,hidden_size3=16,p_dropout=0.2,device=\"mps\")\n",
    "optimizer = optim.Adam(ffnn_fake.parameters(),lr=1e-4)\n",
    "ffnn_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(ffnn_fake,optimizer,max_epochs=6,Xy_train=dataset_subtrain_fake,Xy_val=dataset_valid_fake,taille_batch=1,melanger=True,device=\"mps\",verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "ffnn_fake.eval()\n",
    "pred_train_fake = ffnn_fake.predict(dataset_train_fake.X)\n",
    "pred_dev_fake = ffnn_fake.predict(dataset_dev_fake.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_fake,pred_train_fake,\"entrainement\")\n",
    "evaluation(cible_dev_fake,pred_dev_fake,\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ffnn_fake.state_dict(),\"../modeles/ffnn_fake.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn_fake.eval()\n",
    "data_train[\"ffnn_score\"] = ffnn_fake.predict_proba(tokens_train)\n",
    "data_dev[\"ffnn_score\"] = ffnn_fake.predict_proba(tokens_dev)\n",
    "data_test[\"ffnn_score\"] = ffnn_fake.predict_proba(tokens_test)\n",
    "data_train[\"ffnn_pred\"] = ffnn_fake.predict(tokens_train)\n",
    "data_dev[\"ffnn_pred\"] = ffnn_fake.predict(tokens_dev)\n",
    "data_test[\"ffnn_pred\"] = ffnn_fake.predict(tokens_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combinaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"agg_score\"] = np.mean(data_train[[\"hybrid_score\",\"cnn_score\",\"ffnn_score\"]],axis=1)\n",
    "data_dev[\"agg_score\"] = np.mean(data_dev[[\"hybrid_score\",\"cnn_score\",\"ffnn_score\"]],axis=1)\n",
    "data_test[\"agg_score\"] = np.mean(data_test[[\"hybrid_score\",\"cnn_score\",\"ffnn_score\"]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"agg_pred\"] = np.greater(data_train.agg_score,0.5).astype(int)\n",
    "data_dev[\"agg_pred\"] = np.greater(data_dev.agg_score,0.5).astype(int)\n",
    "data_test[\"agg_pred\"] = np.greater(data_test.agg_score,0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(data_train.false,data_train.agg_pred,\"train\")\n",
    "evaluation(data_dev.false,data_dev.agg_pred,\"dev\")\n",
    "evaluation(data_test.false,data_test.agg_pred,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[\"label\"] = data_train[\"our rating\"].map({\"false\": 0, \"other\": 1, \"partially false\": 2, \"true\": 3})\n",
    "data_dev[\"label\"] = data_dev[\"our rating\"].map({\"false\": 0, \"other\": 1, \"partially false\": 2, \"true\": 3})\n",
    "data_test[\"label\"] = data_test[\"our rating\"].map({\"false\": 0, \"other\": 1, \"partially false\": 2, \"true\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train[[\"agg_score\",\"label\"]].rename(columns={\"agg_score\": \"score\"}).to_csv(\"../donnees/resultats/train_scores_false.csv\",index=False)\n",
    "data_dev[[\"agg_score\",\"label\"]].rename(columns={\"agg_score\": \"score\"}).to_csv(\"../donnees/resultats/dev_scores_false.csv\",index=False)\n",
    "data_test[[\"agg_score\",\"label\"]].rename(columns={\"agg_score\": \"score\"}).to_csv(\"../donnees/resultats/test_scores_false.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IFT714",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
