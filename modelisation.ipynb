{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modélisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from gensim.models import KeyedVectors\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from donnees.nettoyage import FakeNews_Task3_2022_V0\n",
    "from donnees.utils import FakeNewsDataset, ajuster_canaux\n",
    "from embedding import GloVeModel, tokeniser\n",
    "from modeles import CNNRNN, train_seq_fix, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importer et nettoyer les donnees\n",
    "data_train = FakeNews_Task3_2022_V0(\"./donnees/FakeNews_Task3_2022_V0/Task3_train_dev/Task3_english_training.csv\",\"train\")\n",
    "data_dev = FakeNews_Task3_2022_V0(\"./donnees/FakeNews_Task3_2022_V0/Task3_train_dev/Task3_english_dev.csv\",\"dev\")\n",
    "data_test = FakeNews_Task3_2022_V0(\"./donnees/FakeNews_Task3_2022_V0/Task3_Test/English_data_test_release_with_rating.csv\",\"test\")\n",
    "print(f\"Entrainement : {data_train.shape[0]} | Validation : {data_dev.shape[0]} | Test : {data_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajuster les variables\n",
    "data_train[\"full_text\"] = data_train.title+\" \"+data_train.text\n",
    "data_train[\"label$true\"] = np.where(data_train.our_rating==\"true\",1,0)\n",
    "data_train[\"label$false\"] = np.where(data_train.our_rating.str.contains(\"false\"),1,0)\n",
    "data_train[\"label\"] = np.select([data_train.our_rating.str.contains(\"false\"),data_train.our_rating==\"true\"],[0,1],2)\n",
    "data_dev[\"full_text\"] = data_dev.title+\" \"+data_dev.text\n",
    "data_dev[\"label$true\"] = np.where(data_dev.our_rating==\"true\",1,0)\n",
    "data_dev[\"label$false\"] = np.where(data_dev.our_rating.str.contains(\"false\"),1,0)\n",
    "data_dev[\"label\"] = np.select([data_dev.our_rating.str.contains(\"false\"),data_dev.our_rating==\"true\"],[0,1],2)\n",
    "data_test[\"full_text\"] = data_test.title+\" \"+data_test.text\n",
    "data_test[\"label$true\"] = np.where(data_test.our_rating==\"true\",1,0)\n",
    "data_test[\"label$false\"] = np.where(data_test.our_rating.str.contains(\"false\"),1,0)\n",
    "data_test[\"label\"] = np.select([data_test.our_rating.str.contains(\"false\"),data_test.our_rating==\"true\"],[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "# Choisir glove ou word2Vec\n",
    "glove = GloVeModel(\"./donnees/glove.6B/glove.6B.100d.txt\")\n",
    "# word2Vec = KeyedVectors.load_word2vec_format(\"./donnees/GoogleNews-vectors-negative300.bin.gz\",binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees d'entrainement\n",
    "# Si pad=True, retourne un tenseur, sinon retourne une liste\n",
    "tokens_train = tokeniser(data_train.full_text,modele=glove,pad=True)\n",
    "if isinstance(tokens_train,torch.Tensor):\n",
    "    print(tokens_train.shape)\n",
    "else:\n",
    "    print(len(tokens_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles d'entrainement\n",
    "cible_train_real = torch.tensor(data_train[\"label$true\"],dtype=torch.float32)\n",
    "cible_train_fake = torch.tensor(data_train[\"label$false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees de validation\n",
    "# Si pad=True, retourne un tenseur, sinon retourne une liste\n",
    "tokens_dev = tokeniser(data_dev.full_text,modele=glove,pad=True)\n",
    "if isinstance(tokens_dev,torch.Tensor):\n",
    "    print(tokens_dev.shape)\n",
    "else:\n",
    "    print(len(tokens_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles de validation\n",
    "cible_dev_real = torch.tensor(data_dev[\"label$true\"],dtype=torch.float32)\n",
    "cible_dev_fake = torch.tensor(data_dev[\"label$false\"],dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jetoniser les donnees de test\n",
    "# Si pad=True, retourne un tenseur, sinon retourne une liste\n",
    "tokens_test = tokeniser(data_test.full_text,modele=glove,pad=True)\n",
    "if isinstance(tokens_test,torch.Tensor):\n",
    "    print(tokens_test.shape)\n",
    "else:\n",
    "    print(len(tokens_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cibles pour l'evaluation\n",
    "cible_train_dev_real = torch.cat((cible_train_real,cible_dev_real))\n",
    "cible_test_real = torch.tensor(data_test[\"label$true\"],dtype=torch.int)\n",
    "cible_train_dev_fake = torch.cat((cible_train_fake,cible_dev_fake))\n",
    "cible_test_fake = torch.tensor(data_test[\"label$false\"],dtype=torch.int)\n",
    "cible_train_dev = torch.cat((torch.tensor(data_train[\"label\"]),torch.tensor(data_dev[\"label\"])))\n",
    "cible_test = torch.tensor(data_test[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creer datasets pour les modeles \n",
    "# Seulement pour sequences de longueur fixe\n",
    "max_mots = max(tokens_train.shape[1],tokens_dev.shape[1],tokens_test.shape[1])   # ATTENTION! Peut etre tres eleve, peut changer pour une valeur au choix\n",
    "max_mots = 300\n",
    "dataset_train_real = FakeNewsDataset(ajuster_canaux(tokens_train,max_mots),cible_train_real)\n",
    "dataset_dev_real = FakeNewsDataset(ajuster_canaux(tokens_dev,max_mots),cible_dev_real)\n",
    "dataset_test_real = FakeNewsDataset(ajuster_canaux(tokens_test,max_mots),cible_test_real)\n",
    "dataset_train_fake = FakeNewsDataset(ajuster_canaux(tokens_train,max_mots),cible_train_fake)\n",
    "dataset_dev_fake = FakeNewsDataset(ajuster_canaux(tokens_dev,max_mots),cible_dev_fake)\n",
    "dataset_test_fake = FakeNewsDataset(ajuster_canaux(tokens_test,max_mots),cible_test_fake)\n",
    "max_mots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybride CNN-RNN \n",
    "Pour séquences de texte de longueur fixe.  \n",
    "Source : https://www.sciencedirect.com/science/article/pii/S2667096820300070"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"real\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/modelisation/cnn_rnn/real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "hybrid_real = CNNRNN(input_size=100,in_channels=300,out_channels=128,kernel_size=5,hidden_size=32,device=\"mps\")\n",
    "optimizer = optim.Adam(hybrid_real.parameters(),lr=1e-4)\n",
    "hybrid_real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(hybrid_real,dataset_train_real.X.to(\"mps\"))\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(hybrid_real,optimizer,max_epochs=5,Xy_train=dataset_train_real,Xy_val=dataset_dev_real,taille_batch=1,melanger=True,device=\"mps\",writer=writer,verbose=1)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_real = torch.cat((hybrid_real.predict(dataset_train_real.X),hybrid_real.predict(dataset_dev_real.X)))\n",
    "pred_test_real = hybrid_real.predict(dataset_test_real.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_real,pred_train_dev_real,\"entrainement + dev\")\n",
    "evaluation(cible_test_real,pred_test_real,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédire \"fake\" news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/modelisation/cnn_rnn/fake')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialiser le modele\n",
    "hybrid_fake = CNNRNN(input_size=100,in_channels=300,out_channels=128,kernel_size=5,hidden_size=32,device=\"mps\")\n",
    "optimizer = optim.Adam(hybrid_fake.parameters(),lr=1e-4)\n",
    "hybrid_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(hybrid_fake,dataset_train_fake.X.to(\"mps\"))\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrainer le modele\n",
    "train_seq_fix(hybrid_fake,optimizer,max_epochs=5,Xy_train=dataset_train_fake,Xy_val=dataset_dev_fake,taille_batch=1,melanger=True,device=\"mps\",writer=writer,verbose=1)\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generer des predictions\n",
    "pred_train_dev_fake = torch.cat((hybrid_fake.predict(dataset_train_fake.X),hybrid_fake.predict(dataset_dev_fake.X)))\n",
    "pred_test_fake = hybrid_fake.predict(dataset_test_fake.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele\n",
    "evaluation(cible_train_dev_fake,pred_train_dev_fake,\"entrainement + dev\")\n",
    "evaluation(cible_test_fake,pred_test_fake,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinaison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combiner les predictions\n",
    "pred_train_dev = np.select([(pred_train_dev_real==0)*(pred_train_dev_fake==1),(pred_train_dev_real==1)*(pred_train_dev_fake==0)],[0,1],2)\n",
    "pred_test = np.select([(pred_test_real==0)*(pred_test_fake==1),(pred_test_real==1)*(pred_test_fake==0)],[0,1],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluer le modele combine\n",
    "evaluation(cible_train_dev,pred_train_dev,\"entrainement + dev\",multi=True)\n",
    "evaluation(cible_test,pred_test,\"entrainement + dev\",multi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IFT714",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
